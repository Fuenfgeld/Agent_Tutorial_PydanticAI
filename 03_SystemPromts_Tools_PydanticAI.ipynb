{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOZotAwPViVJbSPVuN8NPKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/Agent_Tutorial_PydanticAI/blob/main/03_SystemPromts_Tools_PydanticAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2DixImDenJV"
      },
      "outputs": [],
      "source": [
        "%pip -q install pydantic-ai\n",
        "%pip -q install nest_asyncio\n",
        "%pip -q install logfire"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "keyAntropic = userdata.get('Claude')\n",
        "keyOpenAI = userdata.get('openAI')\n",
        "keyLogFire = userdata.get('logfire')\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = keyOpenAI\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = keyAntropic\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "#logfire.configure(token=keyLogFire)"
      ],
      "metadata": {
        "id": "ckphHZ4TfQXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System Promt"
      ],
      "metadata": {
        "id": "EHgLZ8eNJUIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, system prompts fall into two categories\n",
        "\n",
        "   * Static system prompts: These are known when writing the code and can be defined via the system_prompt parameter of the Agent constructor.\n",
        "   * Dynamic system prompts: These depend in some way on context that isn't known until runtime, and should be defined via functions decorated with @agent.system_prompt.\n",
        "\n"
      ],
      "metadata": {
        "id": "TyEemcqZNA3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.openai import OpenAIChatModel\n",
        "from datetime import date\n",
        "\n",
        "# Define the model\n",
        "model = OpenAIChatModel('gpt-4o-mini')\n",
        "\n",
        "# Create an agent that will use GPT-4o as the LLM\n",
        "# The deps_type=str means we'll pass a string as dependency (patient ID)\n",
        "agent = Agent(\n",
        "    model,\n",
        "    deps_type=str,\n",
        "    system_prompt=\"Use the patient's ID when discussing their medical information.\",\n",
        ")\n",
        "\n",
        "# Add system prompt that includes the patient ID in the context\n",
        "@agent.system_prompt\n",
        "def add_patient_id(ctx: RunContext[str]) -> str:\n",
        "    return f\"The patient's ID you're discussing is {ctx.deps}.\"\n",
        "\n",
        "# Add system prompt that includes today's date for medical record keeping\n",
        "@agent.system_prompt\n",
        "def add_current_date() -> str:\n",
        "    return f'Today\\'s date for the medical record is {date.today()}.'\n",
        "\n",
        "# Run the agent with a query about lab results and include patient ID\n",
        "result = agent.run_sync('What were my latest blood glucose results? also what date is it', deps='PT12345')\n",
        "print(result.output)\n"
      ],
      "metadata": {
        "id": "4UT0A3J9JTey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1: Dynamic System Prompts for Patient Education\n",
        "Instructions:\n",
        "Create a medical education agent that adapts its explanations based on the patient's education level. The agent should:\n",
        "\n",
        "Accept the patient's education level as a dependency (e.g., \"high school\", \"college\", \"medical professional\")\n",
        "Use dynamic system prompts to adjust its language complexity\n",
        "Include the current date in the response"
      ],
      "metadata": {
        "id": "3y0YihZSsO9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.openai import OpenAIChatModel\n",
        "from datetime import date\n",
        "\n",
        "# Define the model\n",
        "model = OpenAIChatModel('gpt-4o-mini')\n",
        "\n",
        "# Create an agent that adapts to patient's education level\n",
        "# TODO: Set up the agent with the appropriate dependency type and system prompt\n",
        "\n",
        "# TODO: Add a dynamic system prompt that adjusts explanation complexity based on education level\n",
        "@agent.system_prompt\n",
        "def adjust_complexity() -> : #add function definition  and docstring\n",
        "    # Implement logic to return different prompt based on education level\n",
        "    pass\n",
        "\n",
        "# TODO: Add a system prompt that includes today's date\n",
        "@agent.system_prompt\n",
        "def add_current_date() -> : #add function definition  and docstring\n",
        "    pass\n",
        "\n",
        "# Test your agent with different education levels\n",
        "result = agent.run_sync('Explain what hypertension is and how it affects the body', deps='high school')\n",
        "print(result.output)\n",
        "\n",
        "# Try with a different education level\n",
        "result = agent.run_sync('Explain what hypertension is and how it affects the body', deps='medical professional')\n",
        "print(result.output)"
      ],
      "metadata": {
        "id": "jEglzMhPsRHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Tools\n",
        "Pydantic AI function tools are a core feature of the PydanticAI framework, allowing AI agents to call external Python functions-known as \"tools\"-to retrieve information or perform actions during a conversation. This system enables agents to go beyond simple text generation and interact with structured data, APIs, or any Python-accessible resource\n",
        "\n",
        "## Schema Extraction\n",
        "\n",
        "When you define a tool with parameters and docstrings, PydanticAI will extract both the parameter types and descriptions to build a detailed schema for the LLM:"
      ],
      "metadata": {
        "id": "e2Idmy3aJN0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.openai import OpenAIChatModel\n",
        "import random\n",
        "\n",
        "\n",
        "def roll_die() -> str:\n",
        "    \"\"\"Roll a six-sided die and return the result.\"\"\"\n",
        "    import random\n",
        "    return str(random.randint(1, 6))\n",
        "\n",
        "model = OpenAIChatModel('gpt-4o-mini')\n",
        "agent = Agent(model, tools=[roll_die])\n",
        "\n",
        "result = agent.run_sync('Roll the die for me')\n",
        "print(result.output)\n",
        "#> The result is 4."
      ],
      "metadata": {
        "id": "EDtBnhg5UbiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Tools and plain tools in PydanticAI both enable AI agents to call Python functions during a conversation, but they differ in how they interact with the agent's context and dependencies.\n",
        "  * Tools\n",
        "\n",
        "    Registered using the @agent.tool decorator or by specifying takes_ctx=True when creating a Tool object.\n",
        "\n",
        "    Accept a RunContext parameter as their first argument. This context provides access to dependencies or other runtime information that the agent may inject for each run.\n",
        "\n",
        "    Useful when a function needs to use external data, session state, or any information managed by the agent at runtime.\n",
        "\n",
        "    Example:\n",
        "\n",
        "\n",
        "  * Plain Tools\n",
        "\n",
        "    Registered using the @agent.tool_plain decorator or by specifying takes_ctx=False when creating a Tool object.\n",
        "\n",
        "    Do not accept a RunContext parameter; they are standard Python functions with only their explicit arguments.\n",
        "\n",
        "    Use these when the tool does not need any agent context or dependencies-just the parameters provided in the function call.\n",
        "\n",
        "    Example:"
      ],
      "metadata": {
        "id": "XAJVq39yUp_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.openai import OpenAIChatModel\n",
        "import random\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = OpenAIChatModel('gpt-4o-mini')\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "    model,\n",
        "    deps_type=str,\n",
        "    system_prompt=(\n",
        "        \"You're a dice game, you should roll the die and see if the number \"\n",
        "        \"you get back matches the user's guess. If so, tell them they're a winner. \"\n",
        "        \"Use the player's name in the response.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "@agent.tool_plain\n",
        "def roll_die() -> str:\n",
        "    \"\"\"Roll a six-sided die and return the result.\"\"\"\n",
        "    return str(random.randint(1, 6))\n",
        "\n",
        "\n",
        "@agent.tool\n",
        "def get_player_name(ctx: RunContext[str]) -> str:\n",
        "    \"\"\"Get the player's name.\"\"\"\n",
        "    return ctx.deps\n",
        "\n",
        "\n",
        "dice_result = agent.run_sync('My guess is 4', deps='Max')\n",
        "\n",
        "\n",
        "print(dice_result.output)\n",
        "#> Congratulations Anne, you guessed correctly! You're a winner!"
      ],
      "metadata": {
        "id": "xeb6l3KqJSR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2: Medical Tools for Patient Assessment\n",
        "Instructions:\n",
        "Implement a medical assessment agent with tools to:\n",
        "\n",
        "Calculate BMI from height and weight (plain tool)\n",
        "Access patient history from their ID (context-aware tool)\n",
        "Make the agent provide a basic health assessment using these tools"
      ],
      "metadata": {
        "id": "m4cqu4A2UAnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.openai import OpenAIChatModel\n",
        "\n",
        "# Define the model\n",
        "model = OpenAIChatModel('gpt-4o-mini')\n",
        "\n",
        "# TODO: Create an agent with a system prompt that establishes a medical assistant role\n",
        "# The agent should accept a patient ID as dependency\n",
        "agent = Agent(\n",
        "    model,\n",
        "    deps_type=str,\n",
        "    system_prompt=\"You are a medical assistant helping with patient assessments.\"\n",
        ")\n",
        "\n",
        "# TODO: Implement a plain tool to calculate BMI from height and weight\n",
        "@agent.tool_plain\n",
        "def calculate_bmi() -> : #TODO add function definition  and docstring\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "# TODO: Implement a context-aware tool to get patient history\n",
        "@agent.tool\n",
        "def get_patient_history() -> : #TODO add function definition  and docstring\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    # Use a mock database based on patient ID\n",
        "    patient_database = {\n",
        "        \"PT12345\": \"History of hypertension, no diabetes, cholesterol: 210mg/dL\",\n",
        "        \"PT67890\": \"Type 2 diabetes, controlled with medication, BMI previously 29.5\"\n",
        "    }\n",
        "    pass\n",
        "\n",
        "# Test your agent\n",
        "result = agent.run_sync('Perform a health assessment. I am 170cm tall and weigh 70kg.', deps='PT12345')\n",
        "print(result.output)"
      ],
      "metadata": {
        "id": "uVP-gcdhs1bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example with multiple Agents"
      ],
      "metadata": {
        "id": "61CbNGYGVdbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "import os\n",
        "from colorama import Fore\n",
        "import logfire\n",
        "from pydantic_ai import Agent, RunContext, Tool\n",
        "from pydantic_ai.models.openai import OpenAIChatModel\n",
        "from pydantic import BaseModel\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "\n",
        "# Configure logging for medical system\n",
        "logfire.configure(token=keyLogFire)\n",
        "\n",
        "# Define the AI model to use\n",
        "model = OpenAIChatModel('gpt-4o-mini')\n",
        "\n",
        "# Define the output model for clinical protocol evaluation\n",
        "class ProtocolQuality(BaseModel):\n",
        "    \"\"\"Clinical Protocol Quality metrics\"\"\"\n",
        "    evidence_level: float  # Evidence level score (1-5)\n",
        "    guideline_adherence: float  # Percentage of adherence to clinical guidelines\n",
        "    review: str  # Clinical review comments\n",
        "\n",
        "# Tool to retrieve the clinical protocol\n",
        "def get_clinical_protocol(ctx: RunContext[str]) -> str:\n",
        "    \"\"\"Get the clinical protocol text\"\"\"\n",
        "    with logfire.span('Agents calls tool with context') as span:\n",
        "        span.set_attribute('context', ctx.deps)\n",
        "    return f\"The clinical protocol is: {ctx.deps}\"\n",
        "\n",
        "# Tool to get the medical standards\n",
        "def get_medical_standards() -> ProtocolQuality:\n",
        "    \"\"\"Get the medical standards for clinical protocols\"\"\"\n",
        "    return ProtocolQuality(evidence_level=4.0, guideline_adherence=90.0, review=\"These are the current medical standards\")\n",
        "\n",
        "# Protocol creation agent\n",
        "protocol_agent = Agent(model=model,\n",
        "                       system_prompt=\"You are an experienced clinician. Create a clinical protocol according to the user's requirements. Return only the protocol text.\")\n",
        "\n",
        "# Protocol review agent\n",
        "protocol_review_agent = Agent(model=model,\n",
        "                              tools=[Tool(get_clinical_protocol, takes_ctx=True),\n",
        "                                     Tool(get_medical_standards, takes_ctx=False)],\n",
        "                              output_type=ProtocolQuality,\n",
        "                              system_prompt=\"You are an experienced medical director. You are reviewing a clinical protocol to ensure it meets quality standards. Provide protocol quality metrics and a review comparing it to medical standards.\")\n",
        "\n",
        "# Run the agents\n",
        "with logfire.span('Calling Protocol Agent') as span:\n",
        "    result = protocol_agent.run_sync(\"Create a diabetes management protocol for primary care that includes HbA1c monitoring schedule.\")\n",
        "    span.set_attribute('result', result.output)\n",
        "\n",
        "print(Fore.YELLOW, result.output)\n",
        "\n",
        "with logfire.span('Calling Review Agent') as span:\n",
        "    result = protocol_review_agent.run_sync(\"Review this protocol and provide quality metrics.\", deps=result.output)\n",
        "    span.set_attribute('result', result.output)\n",
        "print(Fore.CYAN, result.output)"
      ],
      "metadata": {
        "id": "Gu6FpvVsWc_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}