{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP5BBvT1PS6zjQj93YQjemz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/Agent_Tutorial_PydanticAI/blob/main/03_SystemPromts_Tools_PydanticAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2DixImDenJV"
      },
      "outputs": [],
      "source": [
        "%pip -q install pydantic-ai\n",
        "%pip -q install nest_asyncio\n",
        "%pip -q install logfire"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "keyAntropic = userdata.get('Claude')\n",
        "keyOpenAI = userdata.get('openAI')\n",
        "keyLogFire = userdata.get('logfire')\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = keyOpenAI\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = keyAntropic\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "#logfire.configure(token=keyLogFire)"
      ],
      "metadata": {
        "id": "ckphHZ4TfQXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System Promt"
      ],
      "metadata": {
        "id": "EHgLZ8eNJUIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generally, system prompts fall into two categories\n",
        "\n",
        "   * Static system prompts: These are known when writing the code and can be defined via the system_prompt parameter of the Agent constructor.\n",
        "   * Dynamic system prompts: These depend in some way on context that isn't known until runtime, and should be defined via functions decorated with @agent.system_prompt.\n",
        "\n"
      ],
      "metadata": {
        "id": "TyEemcqZNA3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.openai import OpenAIModel\n",
        "from datetime import date\n",
        "\n",
        "# Define the model\n",
        "model = OpenAIModel('gpt-4o-mini')\n",
        "\n",
        "# Create an agent that will use GPT-4o as the LLM\n",
        "# The deps_type=str means we'll pass a string as dependency (patient ID)\n",
        "agent = Agent(\n",
        "    model,\n",
        "    deps_type=str,\n",
        "    system_prompt=\"Use the patient's ID when discussing their medical information.\",\n",
        ")\n",
        "\n",
        "# Add system prompt that includes the patient ID in the context\n",
        "@agent.system_prompt\n",
        "def add_patient_id(ctx: RunContext[str]) -> str:\n",
        "    return f\"The patient's ID you're discussing is {ctx.deps}.\"\n",
        "\n",
        "# Add system prompt that includes today's date for medical record keeping\n",
        "@agent.system_prompt\n",
        "def add_current_date() -> str:\n",
        "    return f'Today\\'s date for the medical record is {date.today()}.'\n",
        "\n",
        "# Run the agent with a query about lab results and include patient ID\n",
        "result = agent.run_sync('What were my latest blood glucose results? also what date is it', deps='PT12345')\n",
        "print(result.output)\n"
      ],
      "metadata": {
        "id": "4UT0A3J9JTey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Tools\n",
        "Pydantic AI function tools are a core feature of the PydanticAI framework, allowing AI agents to call external Python functions-known as \"tools\"-to retrieve information or perform actions during a conversation. This system enables agents to go beyond simple text generation and interact with structured data, APIs, or any Python-accessible resource\n",
        "\n",
        "## Schema Extraction\n",
        "\n",
        "When you define a tool with parameters and docstrings, PydanticAI will extract both the parameter types and descriptions to build a detailed schema for the LLM:"
      ],
      "metadata": {
        "id": "e2Idmy3aJN0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.openai import OpenAIModel\n",
        "import random\n",
        "\n",
        "\n",
        "def roll_die() -> str:\n",
        "    \"\"\"Roll a six-sided die and return the result.\"\"\"\n",
        "    import random\n",
        "    return str(random.randint(1, 6))\n",
        "\n",
        "model = OpenAIModel('gpt-4o-mini')\n",
        "agent = Agent(model, tools=[roll_die])\n",
        "\n",
        "result = agent.run_sync('Roll the die for me')\n",
        "print(result.output)\n",
        "#> The result is 4."
      ],
      "metadata": {
        "id": "EDtBnhg5UbiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Tools and plain tools in PydanticAI both enable AI agents to call Python functions during a conversation, but they differ in how they interact with the agent's context and dependencies.\n",
        "  * Tools\n",
        "\n",
        "    Registered using the @agent.tool decorator or by specifying takes_ctx=True when creating a Tool object.\n",
        "\n",
        "    Accept a RunContext parameter as their first argument. This context provides access to dependencies or other runtime information that the agent may inject for each run.\n",
        "\n",
        "    Useful when a function needs to use external data, session state, or any information managed by the agent at runtime.\n",
        "\n",
        "    Example:\n",
        "\n",
        "\n",
        "  * Plain Tools\n",
        "\n",
        "    Registered using the @agent.tool_plain decorator or by specifying takes_ctx=False when creating a Tool object.\n",
        "\n",
        "    Do not accept a RunContext parameter; they are standard Python functions with only their explicit arguments.\n",
        "\n",
        "    Use these when the tool does not need any agent context or dependencies-just the parameters provided in the function call.\n",
        "\n",
        "    Example:"
      ],
      "metadata": {
        "id": "XAJVq39yUp_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.openai import OpenAIModel\n",
        "import random\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = OpenAIModel('gpt-4o-mini')\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "    model,\n",
        "    deps_type=str,\n",
        "    system_prompt=(\n",
        "        \"You're a dice game, you should roll the die and see if the number \"\n",
        "        \"you get back matches the user's guess. If so, tell them they're a winner. \"\n",
        "        \"Use the player's name in the response.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "@agent.tool_plain\n",
        "def roll_die() -> str:\n",
        "    \"\"\"Roll a six-sided die and return the result.\"\"\"\n",
        "    return str(random.randint(1, 6))\n",
        "\n",
        "\n",
        "@agent.tool\n",
        "def get_player_name(ctx: RunContext[str]) -> str:\n",
        "    \"\"\"Get the player's name.\"\"\"\n",
        "    return ctx.deps\n",
        "\n",
        "\n",
        "dice_result = agent.run_sync('My guess is 4', deps='Max')\n",
        "\n",
        "\n",
        "print(dice_result.output)\n",
        "#> Congratulations Anne, you guessed correctly! You're a winner!"
      ],
      "metadata": {
        "id": "xeb6l3KqJSR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m4cqu4A2UAnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "61CbNGYGVdbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "import os\n",
        "from colorama import Fore\n",
        "import logfire\n",
        "from pydantic_ai import Agent, RunContext, Tool\n",
        "from pydantic_ai.models.openai import OpenAIModel\n",
        "from pydantic import BaseModel\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "\n",
        "# Configure logging for medical system\n",
        "logfire.configure(token=keyLogFire)\n",
        "\n",
        "# Define the AI model to use\n",
        "model = OpenAIModel('gpt-4o-mini')\n",
        "\n",
        "# Define the output model for clinical protocol evaluation\n",
        "class ProtocolQuality(BaseModel):\n",
        "    \"\"\"Clinical Protocol Quality metrics\"\"\"\n",
        "    evidence_level: float  # Evidence level score (1-5)\n",
        "    guideline_adherence: float  # Percentage of adherence to clinical guidelines\n",
        "    review: str  # Clinical review comments\n",
        "\n",
        "# Tool to retrieve the clinical protocol\n",
        "def get_clinical_protocol(ctx: RunContext[str]) -> str:\n",
        "    \"\"\"Get the clinical protocol text\"\"\"\n",
        "    with logfire.span('Agents calls tool with context') as span:\n",
        "        span.set_attribute('context', ctx.deps)\n",
        "    return f\"The clinical protocol is: {ctx.deps}\"\n",
        "\n",
        "# Tool to get the medical standards\n",
        "def get_medical_standards() -> ProtocolQuality:\n",
        "    \"\"\"Get the medical standards for clinical protocols\"\"\"\n",
        "    return ProtocolQuality(evidence_level=4.0, guideline_adherence=90.0, review=\"These are the current medical standards\")\n",
        "\n",
        "# Protocol creation agent\n",
        "protocol_agent = Agent(model=model,\n",
        "                       system_prompt=\"You are an experienced clinician. Create a clinical protocol according to the user's requirements. Return only the protocol text.\")\n",
        "\n",
        "# Protocol review agent\n",
        "protocol_review_agent = Agent(model=model,\n",
        "                              tools=[Tool(get_clinical_protocol, takes_ctx=True),\n",
        "                                     Tool(get_medical_standards, takes_ctx=False)],\n",
        "                              result_type=ProtocolQuality,\n",
        "                              system_prompt=\"You are an experienced medical director. You are reviewing a clinical protocol to ensure it meets quality standards. Provide protocol quality metrics and a review comparing it to medical standards.\")\n",
        "\n",
        "# Run the agents\n",
        "with logfire.span('Calling Protocol Agent') as span:\n",
        "    result = protocol_agent.run_sync(\"Create a diabetes management protocol for primary care that includes HbA1c monitoring schedule.\")\n",
        "    span.set_attribute('result', result.output)\n",
        "\n",
        "print(Fore.YELLOW, result.output)\n",
        "\n",
        "with logfire.span('Calling Review Agent') as span:\n",
        "    result = protocol_review_agent.run_sync(\"Review this protocol and provide quality metrics.\", deps=result.output)\n",
        "    span.set_attribute('result', result.output)\n",
        "print(Fore.CYAN, result.output)"
      ],
      "metadata": {
        "id": "Gu6FpvVsWc_c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}